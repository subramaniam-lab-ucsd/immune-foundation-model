{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cdb623f",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "529d712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scgpt \n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt.model import TransformerModel\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from scgpt.tokenizer import tokenize_and_pad_batch\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import scvi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2898b3e6",
   "metadata": {},
   "source": [
    "## Step 1: Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b03c0ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "czi_reference = sc.read_h5ad(\"../data/datasets/czi_covid_pbmc_5pct.h5ad\") # Obtain reference CZI data for classification labels\n",
    "id2type = dict(enumerate(czi_reference.obs[\"cell_type\"].astype(\"category\").cat.categories)) # create dict to match labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8d81f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_datapath = \"../data/inference/dengue/natural-2/dneg5/\"\n",
    "dengue_data =  sc.read_10x_mtx(dengue_datapath, prefix=\"GSM4670219_Natural2_Dneg5_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e1a82cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 3651 × 33694\n",
       "    var: 'gene_ids'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dengue_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5fd3626b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "## Remove unused values in columns\n",
    "\n",
    "obs_cols = list(dengue_data.obs.columns)\n",
    "print(obs_cols)\n",
    "\n",
    "for colname in obs_cols:\n",
    "    if pd.api.types.is_categorical_dtype(dengue_data.obs[colname]): \n",
    "        dengue_data.obs[colname] = dengue_data.obs[colname].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "25942ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Normalizing total counts ...\n",
      "scGPT - INFO - Binning data ...\n"
     ]
    }
   ],
   "source": [
    "# Run scGPT preprocessor\n",
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",\n",
    "    normalize_total=1e4, # 1. Normalization protocol - sum to 10000 \n",
    "    result_normed_key=\"X_normed\",\n",
    "    log1p=False,  # 2. or True, depending on original training - original training is false\n",
    "    binning=51,\n",
    "    subset_hvg=False,\n",
    "    hvg_flavor=\"seurat_v3\",\n",
    "    hvg_use_key=\"X_normed\",\n",
    "    result_binned_key=\"X_binned\" # 3. Layer for scGPT to work with\n",
    ")\n",
    "preprocessor(dengue_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e174decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute PCA -> kNN -> UMAP\n",
    "\n",
    "# Compute PCA\n",
    "sc.pp.pca(dengue_data)\n",
    "# Compute neighbors and UMAP using PCA embedding\n",
    "sc.pp.neighbors(dengue_data, use_rep=\"X_pca\")\n",
    "sc.tl.umap(dengue_data)\n",
    "# Store UMAP coordinates from PCA in a new layer\n",
    "dengue_data.obsm[\"X_umap_pca\"] = dengue_data.obsm[\"X_umap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d6406fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s5srinivasan/py39env/lib64/python3.9/site-packages/scgpt/model/model.py:77: UserWarning: flash-attn is not installed, using pytorch transformer instead. Set use_fast_transformer=False to avoid this warning. Installing flash-attn is highly recommended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the model config\n",
    "with open(\"../models/scgpt_human/args.json\") as f:\n",
    "    args = json.load(f)\n",
    "\n",
    "# Load vocab\n",
    "vocab = GeneVocab.from_file(\"save/finetuning_czi_5pct_2pct/vocab.json\")\n",
    "vocab.set_default_index(vocab[\"<pad>\"])\n",
    "\n",
    "# Number of cell types in NEW dataset (not original training set)\n",
    "num_cell_types = 97  # update this\n",
    "\n",
    "# Initialize model\n",
    "model = TransformerModel(\n",
    "    ntoken=len(vocab),\n",
    "    d_model=args[\"embsize\"],\n",
    "    nhead=args[\"nheads\"],\n",
    "    d_hid=args[\"d_hid\"],\n",
    "    nlayers=args[\"nlayers\"],\n",
    "    nlayers_cls=args.get(\"n_layers_cls\", 3),\n",
    "    n_cls=num_cell_types,\n",
    "    vocab=vocab,\n",
    "    dropout=args.get(\"dropout\", 0.2),\n",
    "    pad_token=\"<pad>\",\n",
    "    pad_value=-2,\n",
    "    input_emb_style=\"continuous\",\n",
    "    n_input_bins=args.get(\"n_input_bins\", 51),\n",
    "    cell_emb_style=\"cls\",\n",
    "    use_fast_transformer=args.get(\"fast_transformer\", False),\n",
    "    fast_transformer_backend=args.get(\"fast_transformer_backend\", \"flash\"),\n",
    "    pre_norm=args.get(\"pre_norm\", False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b6ed0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"save/finetuning_czi_5pct_2pct/best_model.pt\", map_location=\"cpu\")\n",
    "\n",
    "if all(k.startswith(\"module.\") for k in state_dict.keys()):\n",
    "    state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "43cceea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (encoder): GeneEncoder(\n",
       "    (embedding): Embedding(60697, 512, padding_idx=60694)\n",
       "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (value_encoder): ContinuousValueEncoder(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (linear1): Linear(in_features=1, out_features=512, bias=True)\n",
       "    (activation): ReLU()\n",
       "    (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ExprDecoder(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (cls_decoder): ClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=97, bias=True)\n",
       "  )\n",
       "  (sim): Similarity(\n",
       "    (cos): CosineSimilarity()\n",
       "  )\n",
       "  (creterion_cce): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fd119cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_ids = np.array([vocab[gene] for gene in dengue_data.var_names], dtype=int)\n",
    "\n",
    "counts = dengue_data.layers[\"X_binned\"]  # must match input_layer_key from training\n",
    "\n",
    "tokenized = tokenize_and_pad_batch(\n",
    "    counts,\n",
    "    gene_ids,\n",
    "    max_len=3001,\n",
    "    vocab=vocab,\n",
    "    pad_token=\"<pad>\",\n",
    "    pad_value=-2,\n",
    "    append_cls=True,\n",
    "    include_zero_gene=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "230d680d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (encoder): GeneEncoder(\n",
       "    (embedding): Embedding(60697, 512, padding_idx=60694)\n",
       "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (value_encoder): ContinuousValueEncoder(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (linear1): Linear(in_features=1, out_features=512, bias=True)\n",
       "    (activation): ReLU()\n",
       "    (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ExprDecoder(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (cls_decoder): ClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=97, bias=True)\n",
       "  )\n",
       "  (sim): Similarity(\n",
       "    (cos): CosineSimilarity()\n",
       "  )\n",
       "  (creterion_cce): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define inference dataset\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, tokenized):\n",
    "        self.data = tokenized\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.data.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data[\"genes\"].shape[0]\n",
    "\n",
    "# Create dataset and loader\n",
    "dataset = InferenceDataset(tokenized)\n",
    "loader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=12,     # You can experiment with 512, 1024, or 2048 on A30s\n",
    "    num_workers=8,      # Reduce for GPU-bound tasks\n",
    "    pin_memory=True,    # Enable for GPU\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Move model to GPU and set eval mode\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a720b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_embeddings = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        input_ids = batch[\"genes\"].to(device, non_blocking=True) # add to device\n",
    "        values = batch[\"values\"].to(device, non_blocking=True) # add to device\n",
    "        mask = input_ids.eq(vocab[\"<pad>\"])\n",
    "\n",
    "        # ---------- Step 1: Full prediction (from classification head) ----------\n",
    "        out = model(input_ids, values, src_key_padding_mask=mask, CLS=True)\n",
    "        logits = out[\"cls_output\"]  # Already passed through cls_decoder\n",
    "        preds = logits.argmax(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        # ---------- Step 2: Encoder-only embedding ----------\n",
    "        # 2.1 Embed genes\n",
    "        gene_embed = model.encoder.embedding(input_ids)  # [B, L, D]\n",
    "        gene_embed = model.encoder.enc_norm(gene_embed)\n",
    "\n",
    "        # 2.2 Embed values\n",
    "        value_embed = model.value_encoder(values)  # [B, L, D]\n",
    "\n",
    "        # 2.3 Add them together\n",
    "        x = gene_embed + value_embed\n",
    "\n",
    "        # 2.4 Pass through TransformerEncoder\n",
    "        x = model.transformer_encoder(x, src_key_padding_mask=mask)  # [B, L, D]\n",
    "\n",
    "        # 2.5 Get CLS token (assumes CLS is first token)\n",
    "        cls_embed = x[:, 0, :]  # [B, D]\n",
    "        all_embeddings.append(cls_embed.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e228eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "dengue_data.obs[\"predictions\"] = pd.Categorical(all_preds)\n",
    "\n",
    "# Save encoder embeddings\n",
    "dengue_data.obsm[\"X_scgpt\"] = torch.cat(all_embeddings, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b0884aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 3651 × 33694\n",
       "    obs: 'predictions'\n",
       "    var: 'gene_ids'\n",
       "    uns: 'pca', 'neighbors', 'umap'\n",
       "    obsm: 'bin_edges', 'X_pca', 'X_umap', 'X_umap_pca', 'X_scgpt'\n",
       "    varm: 'PCs'\n",
       "    layers: 'X_normed', 'X_binned'\n",
       "    obsp: 'distances', 'connectivities'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dengue_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6414d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UMAP from X_scgpt\n",
    "sc.pp.neighbors(dengue_data, use_rep=\"X_scgpt\")\n",
    "sc.tl.umap(dengue_data)\n",
    "dengue_data.obsm[\"X_umap_scgpt\"] = dengue_data.obsm[\"X_umap\"]  # copy before it gets overwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4b31e57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CD14-positive monocyte', 'mature NK T cell',\n",
       "       'plasmacytoid dendritic cell', 'classical monocyte',\n",
       "       'T follicular helper cell',\n",
       "       'CD16-positive, CD56-dim natural killer cell, human',\n",
       "       'non-classical monocyte', 'class switched memory B cell',\n",
       "       'monocyte', 'B cell', 'gamma-delta T cell',\n",
       "       'effector CD8-positive, alpha-beta T cell',\n",
       "       'CD16-negative, CD56-bright natural killer cell, human',\n",
       "       'CD8-positive, alpha-beta T cell',\n",
       "       'CD4-positive, alpha-beta T cell', 'naive B cell',\n",
       "       'naive thymus-derived CD4-positive, alpha-beta T cell',\n",
       "       'naive thymus-derived CD8-positive, alpha-beta T cell', 'platelet',\n",
       "       'central memory CD4-positive, alpha-beta T cell',\n",
       "       'regulatory T cell', 'plasmablast', 'T-helper 22 cell',\n",
       "       'CD14-low, CD16-positive monocyte', 'IgG plasma cell',\n",
       "       'IgA plasma cell', 'natural killer cell',\n",
       "       'effector memory CD8-positive, alpha-beta T cell',\n",
       "       'mucosal invariant T cell', 'dendritic cell', 'malignant cell',\n",
       "       'CD8-positive, alpha-beta memory T cell',\n",
       "       'mature alpha-beta T cell', 'erythrocyte',\n",
       "       'myeloid dendritic cell', 'blood cell',\n",
       "       'plasmacytoid dendritic cell, human',\n",
       "       'CD34-positive, CD38-negative hematopoietic stem cell',\n",
       "       'IgG plasmablast', 'CD38-negative naive B cell',\n",
       "       'CD4-positive, alpha-beta memory T cell', 'plasma cell',\n",
       "       'erythroid progenitor cell, mammalian',\n",
       "       'CD14-positive, CD16-negative classical monocyte'], dtype=object)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure predictions are integers (in case they're categorical)\n",
    "pred_ids = dengue_data.obs[\"predictions\"].astype(int)\n",
    "\n",
    "# Map to cell type names using id2type\n",
    "dengue_data.obs[\"predicted_celltype\"] = pred_ids.map(id2type)\n",
    "\n",
    "dengue_data.obs.predicted_celltype.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e8feeda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_data.write_h5ad(dengue_datapath+\"n2dneg5_preds.h5ad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
